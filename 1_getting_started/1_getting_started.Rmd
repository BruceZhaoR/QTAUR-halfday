---
title: "Part 1: Getting Started and Basic Text Analysis"
author: "Kenneth Benoit"
date: "2017-11-15"
output:
  md_document:
    variant: markdown_github
---

## Preliminaries: Installation

First, you need to have **quanteda** installed.  You can do this from inside RStudio, from the Tools...Install Packages menu, or simply using
```{r, eval = FALSE}
install.packages("quanteda")
```

(Optional) You can install some additional corpus data from **quantedaData** using

```{r, eval=FALSE}
## the devtools package is required to install quanteda from Github
devtools::install_github("kbenoit/quantedaData")
```


## Test your setup

Run the rest of this file to test your setup.  You must have quanteda installed in order for this next step to succeed.
```{r}
library("quanteda")
```

Now summarize some texts in the Irish 2010 budget speech corpus:
```{r}
summary(data_corpus_irishbudget2010)
```

Create a document-feature matrix from this corpus, removing stop words:
```{r}
ie_dfm <- dfm(data_corpus_irishbudget2010, remove = c(stopwords("english"), "will"), stem = TRUE)
```

Look at the top occuring features:
```{r}
topfeatures(ie_dfm)
```

Make a word cloud:
```{r, fig.width = 8, fig.height = 8}
dfm_remove(ie_dfm, "\\p{Z}", valuetype = "regex") %>%
  textplot_wordcloud(min.freq = 25, random.order = FALSE)
```

If you got this far, congratulations!


## Three ways to create a `corpus` object

**quanteda can construct a `corpus` object** from several input sources:

1.  a character vector object  
    ```{r}
    my_tiny_corpus <- corpus(data_corpus_inaugural[1:2], metacorpus = list(notes = "Just G.W."))
    summary(my_tiny_corpus)
    ```
    
2.  a `VCorpus` object from the **tm** package, and
    ```{r}
    data(crude, package = "tm")
    my_tm_corpus <- corpus(crude)
    summary(my_tm_corpus, 5)
    ```

3.  a `readtext` object, created by `readtext::readtext()`.

    In most cases you will need to load input files from outside of R, so you will use this third method.  The remainder of this tutorial focuses on `textfile()`, which is designed to be a simple, powerful, and all-purpose method to load texts.

## Using **readtext** to import texts

In the simplest case, we would like to load a set of texts in plain text files from a single directory. To do this, we use the `readtext()` function from the **readtext** package, and use the "glob"" operator `*` to indicate that we want to load multiple files:

```{r message=FALSE}
library("readtext")
readtext("inaugural/*.txt") %>% corpus()
readtext("sotu/*.txt") %>% corpus()
```

Often, we have metadata encoded in the names of the files. For example, the inaugural addresses contain the year and the president's name in the name of the file. With the `docvarsfrom` argument, we can instruct the `textfile` command to consider these elements as document variables.

```{r}
mytf <- readtext("inaugural/*.txt", 
                 docvarsfrom = "filenames", dvsep = "-", docvarnames = c("Year", "President"))
inaug_corpus <- corpus(mytf)
summary(inaug_corpus, 5)
```

If the texts and document variables are stored separately, we can easily add document variables to the corpus, as long as the data frame containing them is of the same length as the texts:

```{r}
SOTUdocvars <- read.csv("SOTU_metadata.csv", stringsAsFactors = FALSE)
SOTUdocvars$Date <- as.Date(SOTUdocvars$Date, "%B %d, %Y")
SOTUdocvars$delivery <- as.factor(SOTUdocvars$delivery)
SOTUdocvars$type <- as.factor(SOTUdocvars$type)
SOTUdocvars$party <- as.factor(SOTUdocvars$party)
SOTUdocvars$nwords <- NULL

sotu_corpus <- readtext("sotu/*.txt", encoding = "UTF-8-BOM") %>% corpus()
docvars(sotu_corpus) <- SOTUdocvars
summary(sotu_corpus, 5)
```

Another common case is that our texts are stored alongside the document variables in a structured file, such as a json, csv or excel file. The textfile command can read in the texts and document variables simultaneously from these files when the name of the field containing the texts is specified.
```{r}
tf1 <- readtext("inaugTexts.xls")
my_corpus <- corpus(tf1, text_field = "inaugSpeech")

tf2 <- readtext("text_example.csv", text_field = "Title")
my_corpus2 <- corpus(tf2)
head(docvars(tf2))  # works on readtext objects too
```

Once the we have loaded a corpus with some document level variables, we can subset the corpus using these variables, create document-feature matrices by aggregating on the variables, or extract the texts concatenated by variable.

```{r}
recentCorpus <- corpus_subset(sotu_corpus, Date >= "1980-01-01")
oldCorpus <- corpus_subset(sotu_corpus, Date < "1980-01-01")

demCorpus <- corpus_subset(sotu_corpus, party == "Democratic")
demFeatures <- dfm(demCorpus) %>%
  dfm_remove(stopwords("english")) %>%
  dfm_trim(min_docfreq = 3, min_count = 5) %>% 
  dfm_weight(type='tfidf') %>% 
  topfeatures()

repCorpus <- corpus_subset(sotu_corpus, party == "Republican") 
repFeatures <- dfm(repCorpus, remove = stopwords("english")) %>%
  dfm_trim(min_docfreq = 3, min_count = 5) %>% 
  dfm_weight(type='tfidf') %>% 
  topfeatures()
```

The `quanteda` corpus objects can be combined using the `+` operator:
```{r}
inaugCorpus <- demCorpus + repCorpus
allFeatures <- dfm(inaugCorpus, remove = stopwords("english")) %>%
  dfm_trim(min_docfreq = 3, min_count = 5) %>% 
  dfm_weight(type = "tfidf") %>% 
  topfeatures()
```

It should also be possible to load a zip file containing texts directly from a url. However, whether this operation succeeds or not can depend on access permission settings on your particular system (i.e. fails on Windows):

```{r}
immigfiles <- readtext("https://github.com/kbenoit/ME114/raw/master/day8/UKimmigTexts.zip")
mycorpus <- corpus(immigfiles)
summary(mycorpus)
```






